{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Age Estimation on Facial Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores whether deep learning can help the Good Seed supermarket chain prevent alcohol sales to underage customers by estimating a shopper’s age from a facial photo taken at checkout. Using a dataset of labeled images, we build a regression model with a convolutional neural network (CNN) to predict age. The process includes exploratory data analysis, model training with transfer learning, and evaluation of prediction accuracy to assess the model’s potential for real-world use.\n",
    "\n",
    "\n",
    "Heather Marie Culligan \n",
    "\n",
    "May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored in the `/datasets/faces/` folder, there you can find\n",
    "- The `final_files` folder with 7.6k photos\n",
    "- The `labels.csv` file with labels, with two columns: `file_name` and `real_age`\n",
    "\n",
    "Given the fact that the number of image files is rather high, it is advisable to avoid reading them all at once, which would greatly consume computational resources. We recommend you build a generator with the ImageDataGenerator generator. This method was explained in Chapter 3, Lesson 7 of this course.\n",
    "\n",
    "The label file can be loaded as an usual CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/datasets/faces/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(labels['real_age'], bins=30, kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df= labels.sample(12, random_state=42).reset_index(drop=True)\n",
    "image_dir= '/datasets/faces/final_files/'\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for i in range(12):\n",
    "    img_path= os.path.join(image_dir, sample_df.loc[i, 'file_name'])\n",
    "    age= sample_df.loc[i, 'real_age']\n",
    "\n",
    "    img= Image.open(img_path)\n",
    "    plt.subplot(3,4, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Age: {int(age)}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(224, 224, 3)):\n",
    "    backbone = ResNet50(\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        include_top=False\n",
    "    )\n",
    "    backbone.trainable = True  # You can freeze layers later if needed\n",
    "\n",
    "    model = Sequential([\n",
    "        backbone,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(1, activation='relu')  # Ensures age predictions are non-negative\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes over 7,000 face images with real age labels. Most individuals are between 20 and 40 years old, with fewer examples at older ages. This imbalance could affect the model’s accuracy for less-represented age groups. The sample images vary in lighting and quality, which makes the task more realistic but also more challenging. These factors will be important to consider during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the necessary functions to train your model on the GPU platform and build a single script containing all of them along with the initialization section.\n",
    "\n",
    "To make this task easier, you can define them in this notebook and run a ready code in the next section to automatically compose the script.\n",
    "\n",
    "The definitions below will be checked by project reviewers as well, so that they can understand how you built the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "    train_gen = datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory='/datasets/faces/final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        seed=12345)\n",
    "\n",
    "    return train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    \n",
    "    test_gen_flow= datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory='/datasets/faces/final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224,224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='validation',\n",
    "        seed=42\n",
    ")\n",
    "\n",
    "    return test_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "\n",
    "    backbone = ResNet50(\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        include_top=False\n",
    "    )\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='relu'))  # Predicts non-negative age values\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0005)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(train_data)\n",
    "\n",
    "    if validation_steps is None:\n",
    "        validation_steps = len(test_data)\n",
    "\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Script to Run on the GPU Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given you've defined the necessary functions you can compose a script for the GPU platform, download it via the \"File|Open...\" menu, and to upload it later for running on the GPU platform.\n",
    "\n",
    "N.B.: The script should include the initialization section as well. An example of this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a script to run on the GPU platform\n",
    "\n",
    "init_str = \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "with open('run_model_on_gpu.py', 'w') as f:\n",
    "    \n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "        \n",
    "    for fn_name in [load_train, load_test, create_model, train_model]:\n",
    "        \n",
    "        src = inspect.getsource(fn_name)\n",
    "        f.write(src)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place the output from the GPU platform as an Markdown cell here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/20\n",
    "356/356 - 35s - loss: 95.3532 - mae: 7.4339 - val_loss: 124.3362 - val_mae: 8.4921\n",
    "Epoch 2/20\n",
    "356/356 - 35s - loss: 76.8372 - mae: 6.6707 - val_loss: 127.6357 - val_mae: 8.6035\n",
    "Epoch 3/20\n",
    "356/356 - 35s - loss: 69.9428 - mae: 6.3992 - val_loss: 91.1531 - val_mae: 7.4454\n",
    "Epoch 4/20\n",
    "356/356 - 35s - loss: 64.4249 - mae: 6.1407 - val_loss: 124.0287 - val_mae: 8.3481\n",
    "Epoch 5/20\n",
    "356/356 - 35s - loss: 52.8486 - mae: 5.5913 - val_loss: 109.1004 - val_mae: 8.2192\n",
    "Epoch 6/20\n",
    "356/356 - 35s - loss: 46.3094 - mae: 5.2223 - val_loss: 85.1038 - val_mae: 7.0332\n",
    "Epoch 7/20\n",
    "356/356 - 35s - loss: 38.2617 - mae: 4.7951 - val_loss: 92.0900 - val_mae: 7.3359\n",
    "Epoch 8/20\n",
    "356/356 - 35s - loss: 37.4804 - mae: 4.7402 - val_loss: 80.0016 - val_mae: 6.7239\n",
    "Epoch 9/20\n",
    "356/356 - 35s - loss: 33.5237 - mae: 4.4271 - val_loss: 83.2579 - val_mae: 6.8529\n",
    "Epoch 10/20\n",
    "356/356 - 35s - loss: 28.5170 - mae: 4.1411 - val_loss: 83.5056 - val_mae: 6.9629\n",
    "Epoch 11/20\n",
    "356/356 - 35s - loss: 27.0142 - mae: 3.9700 - val_loss: 92.1290 - val_mae: 7.1866\n",
    "Epoch 12/20\n",
    "356/356 - 35s - loss: 27.4564 - mae: 4.0428 - val_loss: 185.6307 - val_mae: 11.4591\n",
    "Epoch 13/20\n",
    "356/356 - 35s - loss: 23.7961 - mae: 3.7407 - val_loss: 92.3429 - val_mae: 7.2467\n",
    "Epoch 14/20\n",
    "356/356 - 35s - loss: 24.6167 - mae: 3.8116 - val_loss: 92.4542 - val_mae: 7.1401\n",
    "Epoch 15/20\n",
    "356/356 - 35s - loss: 22.2604 - mae: 3.6746 - val_loss: 82.5822 - val_mae: 6.7841\n",
    "Epoch 16/20\n",
    "356/356 - 35s - loss: 20.1899 - mae: 3.4430 - val_loss: 86.3830 - val_mae: 6.8304\n",
    "Epoch 17/20\n",
    "356/356 - 35s - loss: 17.3425 - mae: 3.2205 - val_loss: 78.4369 - val_mae: 6.6419\n",
    "Epoch 18/20\n",
    "356/356 - 35s - loss: 16.5249 - mae: 3.1295 - val_loss: 81.7731 - val_mae: 6.7226\n",
    "Epoch 19/20\n",
    "356/356 - 35s - loss: 16.6140 - mae: 3.1421 - val_loss: 80.9727 - val_mae: 6.9908\n",
    "Epoch 20/20\n",
    "356/356 - 35s - loss: 17.0187 - mae: 3.1785 - val_loss: 93.4115 - val_mae: 7.6512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained for 20 epochs and showed steady improvement in training accuracy. The validation MAE improved as well, reaching its best around epoch 17 at about 6.6 years. Although there were some fluctuations, the final validation MAE was around 7.6 years. This suggests the model can predict age fairly well, even with variation in the images and uneven age distribution in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model was developed for age verification, its utility extends beyond this single task. The ability to estimate a customer's age from a facial image opens up opportunities for broader retail applications. For example, stores could use age prediction to better understand shopper demographics over time, support targeted marketing strategies, or even enhance security by detecting minors in restricted areas. Additionally, age-aware queue management or personalized service adjustments could improve customer experience. These possibilities highlight how computer vision can contribute not only to compliance but also to business intelligence and operational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
